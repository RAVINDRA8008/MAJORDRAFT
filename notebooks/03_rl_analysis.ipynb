{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de0811e6",
   "metadata": {},
   "source": [
    "# 03 â€” RL Agent Analysis\n",
    "\n",
    "Visualise PPO agent behaviour: augmentation ratios over time,\n",
    "reward trajectory, policy/value losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd3c417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "os.chdir('/content/amers')\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DRIVE_BASE = Path('/content/drive/MyDrive/AMERS')\n",
    "OUT = DRIVE_BASE / 'outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7761ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.load(OUT / 'training_results.pt', map_location='cpu')\n",
    "rl = results.get('rl', {})\n",
    "\n",
    "if rl:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    axes[0, 0].plot(rl['aug_ratio'])\n",
    "    axes[0, 0].set_title('Augmentation Ratio Over Steps')\n",
    "    axes[0, 0].set_ylabel('Ratio')\n",
    "    \n",
    "    axes[0, 1].plot(rl['val_acc'])\n",
    "    axes[0, 1].set_title('Validation Accuracy')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    \n",
    "    axes[1, 0].plot(rl['reward'])\n",
    "    axes[1, 0].set_title('Reward Per Step')\n",
    "    axes[1, 0].set_ylabel('Reward')\n",
    "    axes[1, 0].set_xlabel('Step')\n",
    "    \n",
    "    axes[1, 1].plot(rl['policy_loss'], label='Policy')\n",
    "    axes[1, 1].plot(rl['value_loss'], label='Value')\n",
    "    axes[1, 1].set_title('PPO Losses')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].set_xlabel('Step')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(OUT / 'rl_analysis.png'), dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'Best val acc: {max(rl[\"val_acc\"]):.4f} at step {np.argmax(rl[\"val_acc\"])+1}')\n",
    "    print(f'Mean aug ratio: {np.mean(rl[\"aug_ratio\"]):.3f}')\n",
    "else:\n",
    "    print('No RL results found. Run training first.')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
