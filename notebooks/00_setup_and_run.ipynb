{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08676575",
   "metadata": {},
   "source": [
    "# AMERS — Bulletproof Setup & Run (Google Colab)\n",
    "\n",
    "**Every cell is self-contained.** You can re-run any cell after a runtime restart — just run Cell 1 (Mount Drive) first, then jump to wherever you left off.\n",
    "\n",
    "- Cells **skip automatically** if their output already exists on Drive\n",
    "- All progress is saved to Google Drive — nothing is lost on restart\n",
    "- A **Status Dashboard** (Cell 3) shows what's done and what's pending\n",
    "\n",
    "**Requirements:** Colab Pro (GPU runtime), DEAP + IEMOCAP datasets on Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da9a661",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive & Check GPU (ALWAYS RUN THIS FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdf259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════╗\n",
    "# ║  RUN THIS CELL FIRST after every restart    ║\n",
    "# ╚══════════════════════════════════════════════╝\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Mount Drive (idempotent — safe to re-run)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Verify GPU\n",
    "import torch\n",
    "print(f'PyTorch {torch.__version__}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    !nvidia-smi | head -12\n",
    "else:\n",
    "    print('WARNING: No GPU detected! Go to Runtime → Change runtime type → GPU')\n",
    "\n",
    "# Quick sanity check\n",
    "DRIVE_BASE = Path('/content/drive/MyDrive/AMERS')\n",
    "if DRIVE_BASE.exists():\n",
    "    print(f'\\n Drive base found: {DRIVE_BASE}')\n",
    "else:\n",
    "    print(f'\\n Drive base NOT found — will be created in Cell 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1657779a",
   "metadata": {},
   "source": [
    "## 2. Clone Repo + Install Dependencies + Setup Dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aae1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Self-contained: no dependency on previous cell variables ──\n",
    "import os, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "GITHUB_USER = 'RAVINDRA8008'\n",
    "REPO_NAME   = 'MAJORDRAFT'\n",
    "REPO_DIR    = '/content/amers'\n",
    "DRIVE_BASE  = Path('/content/drive/MyDrive/AMERS')\n",
    "\n",
    "# If repo is PRIVATE, paste your token here:\n",
    "GITHUB_TOKEN = ''  # e.g. 'ghp_xxxxxxxxxxxxxxxxxxxx'\n",
    "\n",
    "# ── Clone or pull ──\n",
    "if GITHUB_TOKEN:\n",
    "    url = f'https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
    "else:\n",
    "    url = f'https://github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    r = subprocess.run(['git', 'clone', url, REPO_DIR], capture_output=True, text=True)\n",
    "    if r.returncode != 0:\n",
    "        print(f'Clone failed: {r.stderr}')\n",
    "        print('If private repo: set GITHUB_TOKEN above, or make repo public')\n",
    "        raise RuntimeError('git clone failed')\n",
    "    print('Repository cloned.')\n",
    "else:\n",
    "    subprocess.run(['git', '-C', REPO_DIR, 'pull', '--ff-only'], capture_output=True)\n",
    "    print('Repository updated (git pull).')\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "# ── Install deps (pip caches — fast on re-run) ──\n",
    "!pip install -q -r requirements.txt 2>&1 | tail -3\n",
    "print('Dependencies ready.')\n",
    "\n",
    "# ── Create ALL Drive directories ──\n",
    "for sub in [\n",
    "    'data/deap/raw', 'data/deap/processed',\n",
    "    'data/iemocap/raw', 'data/iemocap/processed',\n",
    "    'outputs/checkpoints/eeg', 'outputs/checkpoints/gan',\n",
    "    'outputs/checkpoints/speech', 'outputs/checkpoints/fusion',\n",
    "    'outputs/checkpoints/rl',\n",
    "    'outputs', 'logs',\n",
    "]:\n",
    "    (DRIVE_BASE / sub).mkdir(parents=True, exist_ok=True)\n",
    "print('Drive directory structure ready.')\n",
    "print(f'\\nAll good! Working dir: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26561b88",
   "metadata": {},
   "source": [
    "## 3. STATUS DASHBOARD — Run anytime to see progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bac8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════════════════╗\n",
    "# ║  STATUS DASHBOARD — shows what's done & what's pending  ║\n",
    "# ╚══════════════════════════════════════════════════════════╝\n",
    "from pathlib import Path\n",
    "\n",
    "DB = Path('/content/drive/MyDrive/AMERS')\n",
    "CKPT = DB / 'outputs' / 'checkpoints'\n",
    "\n",
    "checks = [\n",
    "    ('DEAP extracted',        bool(list((DB/'data/deap/raw').glob('*.dat')))),\n",
    "    ('IEMOCAP extracted',     bool(list((DB/'data/iemocap/raw').glob('Session*')))),\n",
    "    ('DEAP preprocessed',     (DB/'data/deap/processed/s01_features.npy').exists()),\n",
    "    ('IEMOCAP preprocessed',  (DB/'data/iemocap/processed/session1_features.npy').exists()),\n",
    "    ('EEG encoder trained',   (CKPT/'eeg/eeg_encoder_final.pt').exists()),\n",
    "    ('GAN trained',           (CKPT/'gan/gan_final.pt').exists()),\n",
    "    ('Speech encoder trained',(CKPT/'speech/speech_encoder_final.pt').exists()),\n",
    "    ('Fusion trained',        (CKPT/'fusion/best_fusion_baseline.pt').exists()),\n",
    "    ('RL agent trained',      (CKPT/'rl/ppo_agent_final.pt').exists()),\n",
    "    ('Evaluation done',       (DB/'outputs/report.md').exists()),\n",
    "]\n",
    "\n",
    "print('='*52)\n",
    "print('  AMERS Pipeline Status')\n",
    "print('='*52)\n",
    "all_done = True\n",
    "for name, done in checks:\n",
    "    icon = ' DONE' if done else ' PENDING'\n",
    "    print(f'  {icon}  {name}')\n",
    "    if not done:\n",
    "        all_done = False\n",
    "print('='*52)\n",
    "\n",
    "if all_done:\n",
    "    print('  ALL STAGES COMPLETE! Jump to Cell 14 to view results.')\n",
    "else:\n",
    "    # Find first pending\n",
    "    for i, (name, done) in enumerate(checks):\n",
    "        if not done:\n",
    "            cell_map = {0: 4, 1: 5, 2: 6, 3: 7, 4: 8, 5: 9, 6: 10, 7: 11, 8: 12, 9: 13}\n",
    "            print(f'\\n  Next step: run Cell {cell_map.get(i, \"?\")} ({name})'  )\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e792226e",
   "metadata": {},
   "source": [
    "## 4. Extract DEAP Dataset (skips if already done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a4cffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Self-contained: DEAP extraction ──\n",
    "import zipfile, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "DRIVE_BASE = Path('/content/drive/MyDrive/AMERS')\n",
    "DEAP_RAW = DRIVE_BASE / 'data' / 'deap' / 'raw'\n",
    "DEAP_RAW.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DEAP_FILE_ID = '1Gl-itg2kqDYW1MH5K3CTlzJUFT69ZrU5'\n",
    "\n",
    "dat_files = list(DEAP_RAW.glob('*.dat'))\n",
    "if len(dat_files) >= 32:\n",
    "    print(f'SKIP: DEAP already extracted ({len(dat_files)} .dat files)')\n",
    "else:\n",
    "    deap_zip = DRIVE_BASE / 'data' / 'deap' / 'deap_dataset.zip'\n",
    "    if not deap_zip.exists():\n",
    "        print('Downloading DEAP zip from Drive...')\n",
    "        !gdown --id {DEAP_FILE_ID} -O {str(deap_zip)}\n",
    "\n",
    "    print('Extracting DEAP .dat files...')\n",
    "    with zipfile.ZipFile(deap_zip, 'r') as z:\n",
    "        dat_entries = [n for n in z.namelist() if n.endswith('.dat')]\n",
    "        print(f'  Found {len(dat_entries)} .dat files inside zip')\n",
    "        for entry in dat_entries:\n",
    "            z.extract(entry, DEAP_RAW)\n",
    "\n",
    "    # Flatten any subdirectories\n",
    "    for f in list(DEAP_RAW.rglob('*.dat')):\n",
    "        dest = DEAP_RAW / f.name\n",
    "        if f != dest:\n",
    "            shutil.move(str(f), str(dest))\n",
    "    for d in sorted(DEAP_RAW.rglob('*'), reverse=True):\n",
    "        if d.is_dir():\n",
    "            try: d.rmdir()\n",
    "            except OSError: pass\n",
    "\n",
    "    final = list(DEAP_RAW.glob('*.dat'))\n",
    "    print(f'DONE: {len(final)} .dat files in {DEAP_RAW}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a460f",
   "metadata": {},
   "source": [
    "## 5. Extract IEMOCAP Dataset (skips if already done)\n",
    "Extracts to **local SSD** first (fast), then copies to Drive. Takes ~5-10 min on first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41edba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Self-contained: IEMOCAP extraction ──\n",
    "import zipfile, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "DRIVE_BASE = Path('/content/drive/MyDrive/AMERS')\n",
    "IEMOCAP_RAW = DRIVE_BASE / 'data' / 'iemocap' / 'raw'\n",
    "IEMOCAP_RAW.mkdir(parents=True, exist_ok=True)\n",
    "LOCAL_TMP = Path('/content/iemocap_extract_tmp')\n",
    "\n",
    "IEMOCAP_FILE_ID = '1lIzIlkQxwiWS4zeld-kQf87zbvPpS9gd'\n",
    "\n",
    "sessions = list(IEMOCAP_RAW.glob('Session*'))\n",
    "if len(sessions) >= 5:\n",
    "    print(f'SKIP: IEMOCAP already extracted ({len(sessions)} sessions)')\n",
    "else:\n",
    "    iemocap_zip = DRIVE_BASE / 'data' / 'iemocap' / 'iemocap_dataset.zip'\n",
    "    if not iemocap_zip.exists():\n",
    "        print('Downloading IEMOCAP zip from Drive...')\n",
    "        !gdown --id {IEMOCAP_FILE_ID} -O {str(iemocap_zip)}\n",
    "\n",
    "    # Step 1: Unzip to local SSD (fast)\n",
    "    LOCAL_TMP.mkdir(parents=True, exist_ok=True)\n",
    "    print('Step 1/3: Extracting outer zip to local SSD...')\n",
    "    with zipfile.ZipFile(iemocap_zip, 'r') as z:\n",
    "        z.extractall(LOCAL_TMP)\n",
    "    print('  Done.')\n",
    "\n",
    "    # Step 2: Extract inner tar.gz (if any)\n",
    "    tar_files = list(LOCAL_TMP.rglob('*.tar.gz'))\n",
    "    for tgz in tar_files:\n",
    "        print(f'Step 2/3: Extracting {tgz.name} (~5 min)...')\n",
    "        !cd {str(LOCAL_TMP)} && tar xzf {str(tgz)}\n",
    "        tgz.unlink()\n",
    "        print('  Done.')\n",
    "\n",
    "    # Find Session dirs\n",
    "    session_dirs = sorted([d for d in LOCAL_TMP.rglob('Session*') if d.is_dir() and d.name.startswith('Session')])\n",
    "    print(f'  Found {len(session_dirs)} Session dirs locally')\n",
    "\n",
    "    # Step 3: Copy to Drive\n",
    "    print('Step 3/3: Copying to Drive...')\n",
    "    for sd in session_dirs:\n",
    "        dest = IEMOCAP_RAW / sd.name\n",
    "        if not dest.exists():\n",
    "            print(f'  {sd.name}...', end=' ', flush=True)\n",
    "            shutil.copytree(str(sd), str(dest))\n",
    "            print('done')\n",
    "        else:\n",
    "            print(f'  {sd.name} already on Drive')\n",
    "\n",
    "    # Cleanup\n",
    "    shutil.rmtree(LOCAL_TMP, ignore_errors=True)\n",
    "\n",
    "    final = list(IEMOCAP_RAW.glob('Session*'))\n",
    "    print(f'\\nDONE: {len(final)} sessions in {IEMOCAP_RAW}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8d248d",
   "metadata": {},
   "source": [
    "## 6. Preprocess DEAP (EEG → Differential Entropy features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377d7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Self-contained: Preprocess DEAP ──\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir('/content/amers')\n",
    "DB = Path('/content/drive/MyDrive/AMERS')\n",
    "sentinel = DB / 'data' / 'deap' / 'processed' / 's01_features.npy'\n",
    "\n",
    "if sentinel.exists():\n",
    "    n = len(list((DB / 'data/deap/processed').glob('*_features.npy')))\n",
    "    print(f'SKIP: DEAP already preprocessed ({n} subject feature files)')\n",
    "else:\n",
    "    print('Preprocessing DEAP...')\n",
    "    !python scripts/preprocess_deap.py --config config/default.yaml\n",
    "    if sentinel.exists():\n",
    "        print('DONE: DEAP preprocessing complete')\n",
    "    else:\n",
    "        print('WARNING: Preprocessing ran but sentinel file not found — check output above')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d848b54",
   "metadata": {},
   "source": [
    "## 7. Preprocess IEMOCAP (Speech → MFCC features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b5baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Self-contained: Preprocess IEMOCAP ──\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir('/content/amers')\n",
    "DB = Path('/content/drive/MyDrive/AMERS')\n",
    "sentinel = DB / 'data' / 'iemocap' / 'processed' / 'session1_features.npy'\n",
    "\n",
    "if sentinel.exists():\n",
    "    n = len(list((DB / 'data/iemocap/processed').glob('*_features.npy')))\n",
    "    print(f'SKIP: IEMOCAP already preprocessed ({n} session feature files)')\n",
    "else:\n",
    "    print('Preprocessing IEMOCAP (this may take several minutes)...')\n",
    "    !python scripts/preprocess_iemocap.py --config config/default.yaml\n",
    "    if sentinel.exists():\n",
    "        print('DONE: IEMOCAP preprocessing complete')\n",
    "    else:\n",
    "        print('WARNING: Preprocessing ran but sentinel file not found — check output above')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f49b1",
   "metadata": {},
   "source": [
    "## 8. Train EEG Encoder (pre-train on DEAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11c3f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Self-contained: Train EEG Encoder ──\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir('/content/amers')\n",
    "CKPT = Path('/content/drive/MyDrive/AMERS/outputs/checkpoints')\n",
    "sentinel = CKPT / 'eeg' / 'eeg_encoder_final.pt'\n",
    "\n",
    "if sentinel.exists():\n",
    "    sz = sentinel.stat().st_size / 1024\n",
    "    print(f'SKIP: EEG encoder already trained ({sz:.0f} KB checkpoint)')\n",
    "else:\n",
    "    print('Training EEG encoder...')\n",
    "    !python scripts/train_eeg.py --config config/default.yaml\n",
    "    if sentinel.exists():\n",
    "        print('DONE: EEG encoder training complete')\n",
    "    else:\n",
    "        print('ERROR: Training finished but checkpoint not found — check output above')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b4b5d4",
   "metadata": {},
   "source": [
    "## 9. Train GAN (Conditional GAN on EEG features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068c1100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Self-contained: Train GAN ──\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir('/content/amers')\n",
    "CKPT = Path('/content/drive/MyDrive/AMERS/outputs/checkpoints')\n",
    "sentinel = CKPT / 'gan' / 'gan_final.pt'\n",
    "\n",
    "if sentinel.exists():\n",
    "    sz = sentinel.stat().st_size / 1024\n",
    "    print(f'SKIP: GAN already trained ({sz:.0f} KB checkpoint)')\n",
    "else:\n",
    "    print('Training Conditional GAN (100 epochs)...')\n",
    "    !python scripts/train_gan.py --config config/default.yaml\n",
    "    if sentinel.exists():\n",
    "        print('DONE: GAN training complete')\n",
    "    else:\n",
    "        print('ERROR: Training finished but checkpoint not found — check output above')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ff62cf",
   "metadata": {},
   "source": [
    "## 10. Train Speech Encoder (CNN-LSTM on IEMOCAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705c1faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Self-contained: Train Speech Encoder ──\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir('/content/amers')\n",
    "CKPT = Path('/content/drive/MyDrive/AMERS/outputs/checkpoints')\n",
    "sentinel = CKPT / 'speech' / 'speech_encoder_final.pt'\n",
    "\n",
    "if sentinel.exists():\n",
    "    sz = sentinel.stat().st_size / 1024\n",
    "    print(f'SKIP: Speech encoder already trained ({sz:.0f} KB checkpoint)')\n",
    "else:\n",
    "    print('Training Speech Encoder (30 epochs)...')\n",
    "    !python scripts/train_speech.py --config config/default.yaml\n",
    "    if sentinel.exists():\n",
    "        print('DONE: Speech encoder training complete')\n",
    "    else:\n",
    "        print('ERROR: Training finished but checkpoint not found — check output above')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f36af",
   "metadata": {},
   "source": [
    "## 11. Train Fusion Classifier (baseline, no RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0212a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Self-contained: Train Fusion Classifier ──\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir('/content/amers')\n",
    "CKPT = Path('/content/drive/MyDrive/AMERS/outputs/checkpoints')\n",
    "sentinel = CKPT / 'fusion' / 'best_fusion_baseline.pt'\n",
    "\n",
    "if sentinel.exists():\n",
    "    sz = sentinel.stat().st_size / 1024\n",
    "    print(f'SKIP: Fusion classifier already trained ({sz:.0f} KB checkpoint)')\n",
    "else:\n",
    "    # Check prerequisites\n",
    "    missing = []\n",
    "    if not (CKPT / 'eeg' / 'eeg_encoder_final.pt').exists():\n",
    "        missing.append('EEG encoder (Cell 8)')\n",
    "    if not (CKPT / 'speech' / 'speech_encoder_final.pt').exists():\n",
    "        missing.append('Speech encoder (Cell 10)')\n",
    "    if missing:\n",
    "        print(f'BLOCKED: Need to train first: {\", \".join(missing)}')\n",
    "    else:\n",
    "        print('Training Fusion Classifier (50 epochs)...')\n",
    "        !python scripts/train_fusion.py --config config/default.yaml\n",
    "        if sentinel.exists():\n",
    "            print('DONE: Fusion training complete')\n",
    "        else:\n",
    "            print('ERROR: Training finished but checkpoint not found — check output above')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebade9d",
   "metadata": {},
   "source": [
    "## 12. Train RL Agent (PPO augmentation control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be99ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Self-contained: Train RL Agent ──\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir('/content/amers')\n",
    "CKPT = Path('/content/drive/MyDrive/AMERS/outputs/checkpoints')\n",
    "sentinel = CKPT / 'rl' / 'ppo_agent_final.pt'\n",
    "\n",
    "if sentinel.exists():\n",
    "    sz = sentinel.stat().st_size / 1024\n",
    "    print(f'SKIP: RL agent already trained ({sz:.0f} KB checkpoint)')\n",
    "else:\n",
    "    # Check all prerequisites\n",
    "    missing = []\n",
    "    if not (CKPT / 'gan' / 'gan_final.pt').exists():\n",
    "        missing.append('GAN (Cell 9)')\n",
    "    if not (CKPT / 'eeg' / 'eeg_encoder_final.pt').exists():\n",
    "        missing.append('EEG encoder (Cell 8)')\n",
    "    if not (CKPT / 'speech' / 'speech_encoder_final.pt').exists():\n",
    "        missing.append('Speech encoder (Cell 10)')\n",
    "    if missing:\n",
    "        print(f'BLOCKED: Need to train first: {\", \".join(missing)}')\n",
    "    else:\n",
    "        print('Training RL Agent (PPO)...')\n",
    "        !python scripts/train_rl.py --config config/default.yaml\n",
    "        if sentinel.exists():\n",
    "            print('DONE: RL training complete')\n",
    "        else:\n",
    "            print('ERROR: Training finished but checkpoint not found — check output above')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfa91d7",
   "metadata": {},
   "source": [
    "## 13. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f288496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Self-contained: Evaluate ──\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir('/content/amers')\n",
    "OUT = Path('/content/drive/MyDrive/AMERS/outputs')\n",
    "CKPT = OUT / 'checkpoints'\n",
    "sentinel = OUT / 'report.md'\n",
    "\n",
    "if sentinel.exists():\n",
    "    print(f'SKIP: Evaluation already done (report at {sentinel})')\n",
    "    print('Delete the report file and re-run to regenerate.')\n",
    "else:\n",
    "    # Check prerequisites\n",
    "    missing = []\n",
    "    if not (CKPT / 'eeg' / 'eeg_encoder_final.pt').exists():\n",
    "        missing.append('EEG encoder (Cell 8)')\n",
    "    if not (CKPT / 'speech' / 'speech_encoder_final.pt').exists():\n",
    "        missing.append('Speech encoder (Cell 10)')\n",
    "    has_rl = (CKPT / 'rl' / 'best_fusion.pt').exists()\n",
    "    has_bl = (CKPT / 'fusion' / 'best_fusion_baseline.pt').exists()\n",
    "    if not has_rl and not has_bl:\n",
    "        missing.append('Fusion or RL (Cell 11 or 12)')\n",
    "    if missing:\n",
    "        print(f'BLOCKED: Need: {\", \".join(missing)}')\n",
    "    else:\n",
    "        tag = 'RL-tuned' if has_rl else 'baseline'\n",
    "        print(f'Evaluating {tag} model...')\n",
    "        !python scripts/evaluate.py --config config/default.yaml\n",
    "        if sentinel.exists():\n",
    "            print('DONE: Evaluation complete — see Cell 14 for results')\n",
    "        else:\n",
    "            print('WARNING: Evaluation ran but report not generated — check output above')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c266ed26",
   "metadata": {},
   "source": [
    "## 14. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Self-contained: View results ──\n",
    "from pathlib import Path\n",
    "from IPython.display import Image, display, Markdown\n",
    "\n",
    "OUT = Path('/content/drive/MyDrive/AMERS/outputs')\n",
    "\n",
    "# Confusion matrix\n",
    "cm = OUT / 'confusion_matrix.png'\n",
    "if cm.exists():\n",
    "    print('=== Confusion Matrix ===')\n",
    "    display(Image(str(cm), width=500))\n",
    "else:\n",
    "    print('No confusion matrix yet (run Cell 13 first)')\n",
    "\n",
    "# t-SNE\n",
    "tsne = OUT / 'tsne_embeddings.png'\n",
    "if tsne.exists():\n",
    "    print('\\n=== t-SNE Embeddings ===')\n",
    "    display(Image(str(tsne), width=500))\n",
    "\n",
    "# Report\n",
    "report = OUT / 'report.md'\n",
    "if report.exists():\n",
    "    print('\\n=== Evaluation Report ===')\n",
    "    display(Markdown(report.read_text()))\n",
    "else:\n",
    "    print('No report yet (run Cell 13 first)')\n",
    "\n",
    "# Loss/accuracy plots\n",
    "for name in ['eeg_loss.png', 'gan_loss.png', 'speech_loss.png', 'speech_acc.png',\n",
    "             'fusion_loss.png', 'fusion_acc.png', 'rl_aug_ratios.png']:\n",
    "    p = OUT / name\n",
    "    if p.exists():\n",
    "        print(f'\\n=== {name} ===')\n",
    "        display(Image(str(p), width=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66355e21",
   "metadata": {},
   "source": [
    "## 15. Push Updates to GitHub (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbde31d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to push changes from Colab back to GitHub\n",
    "# import os; os.chdir('/content/amers')\n",
    "# !git add -A && git commit -m 'Update from Colab' && git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
