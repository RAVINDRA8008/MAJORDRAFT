{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08676575",
   "metadata": {},
   "source": [
    "# AMERS — Setup & Run (Google Colab)\n",
    "\n",
    "This notebook sets up the full environment on Colab Pro, mounts Drive,\n",
    "clones the repo, installs dependencies, and walks through the training pipeline.\n",
    "\n",
    "**Requirements:** Colab Pro (GPU runtime), datasets on Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3b16eb",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive & Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "515d65d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/bin/bash: line 1: nvidia-smi: command not found\n",
      "PyTorch 2.10.0+cpu, CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!nvidia-smi\n",
    "import torch\n",
    "print(f'PyTorch {torch.__version__}, CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bd269b",
   "metadata": {},
   "source": [
    "## 2. Clone Repository & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97dba4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Repository updated.\n",
      "\n",
      "✓ Dependencies installed.\n"
     ]
    }
   ],
   "source": [
    "import os, subprocess\n",
    "\n",
    "# ── Configuration ──\n",
    "GITHUB_USER = 'RAVINDRA8008'\n",
    "REPO_NAME   = 'MAJORDRAFT'\n",
    "REPO_DIR    = '/content/amers'\n",
    "\n",
    "# If your repo is PRIVATE, generate a token at:\n",
    "#   https://github.com/settings/tokens → \"Generate new token (classic)\" → check \"repo\" scope\n",
    "# Then paste it below (remove the quotes placeholder):\n",
    "GITHUB_TOKEN = ''  # e.g. 'ghp_xxxxxxxxxxxxxxxxxxxx'\n",
    "\n",
    "# Build URL (with or without token)\n",
    "if GITHUB_TOKEN:\n",
    "    REPO_URL = f'https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
    "else:\n",
    "    REPO_URL = f'https://github.com/{GITHUB_USER}/{REPO_NAME}.git'\n",
    "\n",
    "# Clone or pull\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    result = subprocess.run(['git', 'clone', REPO_URL, REPO_DIR], capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(f'Clone failed: {result.stderr}')\n",
    "        print('\\n⚠️  If the repo is private, either:')\n",
    "        print('   1. Make it public: GitHub → Repo Settings → Danger Zone → Change visibility')\n",
    "        print('   2. Set GITHUB_TOKEN above with a personal access token')\n",
    "        raise RuntimeError('Git clone failed')\n",
    "    print('✓ Repository cloned.')\n",
    "else:\n",
    "    subprocess.run(['git', '-C', REPO_DIR, 'pull'], check=True)\n",
    "    print('✓ Repository updated.')\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "!pip install -q -r requirements.txt\n",
    "print('\\n✓ Dependencies installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacbe09b",
   "metadata": {},
   "source": [
    "## 3. Setup Drive Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35a1e55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ /content/drive/MyDrive/AMERS/data/deap/raw\n",
      "  ✓ /content/drive/MyDrive/AMERS/data/deap/processed\n",
      "  ✓ /content/drive/MyDrive/AMERS/data/iemocap/raw\n",
      "  ✓ /content/drive/MyDrive/AMERS/data/iemocap/processed\n",
      "  ✓ /content/drive/MyDrive/AMERS/checkpoints\n",
      "  ✓ /content/drive/MyDrive/AMERS/outputs\n",
      "  ✓ /content/drive/MyDrive/AMERS/logs\n",
      "\n",
      "✓ Drive structure ready.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DRIVE_BASE = Path('/content/drive/MyDrive/AMERS')\n",
    "\n",
    "dirs = [\n",
    "    DRIVE_BASE / 'data' / 'deap' / 'raw',\n",
    "    DRIVE_BASE / 'data' / 'deap' / 'processed',\n",
    "    DRIVE_BASE / 'data' / 'iemocap' / 'raw',\n",
    "    DRIVE_BASE / 'data' / 'iemocap' / 'processed',\n",
    "    DRIVE_BASE / 'checkpoints',\n",
    "    DRIVE_BASE / 'outputs',\n",
    "    DRIVE_BASE / 'logs',\n",
    "]\n",
    "\n",
    "for d in dirs:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "    print(f'  ✓ {d}')\n",
    "\n",
    "print('\\n✓ Drive structure ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82f64c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /content/drive/MyDrive/AMERS/data/iemocap/raw/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d86eb",
   "metadata": {},
   "source": [
    "## 4. Extract Datasets from Drive\n",
    "\n",
    "Make sure you've uploaded the DEAP and IEMOCAP zip/tar files to your Drive.\n",
    "\n",
    "- **DEAP:** File ID `1Gl-itg2kqDYW1MH5K3CTlzJUFT69ZrU5`\n",
    "- **IEMOCAP:** File ID `1lIzIlkQxwiWS4zeld-kQf87zbvPpS9gd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5074429c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting DEAP .dat files ...\n",
      "  Found 32 .dat files inside zip\n",
      "  ✓ DEAP: 32 .dat files ready\n",
      "Extracting IEMOCAP ...\n",
      "  Zip has 1 entries\n",
      "    IEMOCAP_full_release_withoutVideos.tar.gz\n",
      "  .wav files: 0, .txt files: 0\n",
      "  Top-level items in raw/: ['IEMOCAP_full_release_withoutVideos.tar.gz']\n",
      "  Session* dirs found (recursive): 0\n",
      "  ⚠️  No Session* directories found. Checking .wav locations...\n",
      "  Found 0 .wav files on disk\n",
      "  ✓ IEMOCAP: 0 sessions ready\n"
     ]
    }
   ],
   "source": [
    "import zipfile, tarfile, shutil\n",
    "\n",
    "# ── DEAP ──\n",
    "DEAP_FILE_ID = '1Gl-itg2kqDYW1MH5K3CTlzJUFT69ZrU5'\n",
    "DEAP_RAW = DRIVE_BASE / 'data' / 'deap' / 'raw'\n",
    "\n",
    "if not list(DEAP_RAW.glob('*.dat')):\n",
    "    deap_zip = DRIVE_BASE / 'data' / 'deap' / 'deap_dataset.zip'\n",
    "    if not deap_zip.exists():\n",
    "        !gdown --id {DEAP_FILE_ID} -O {str(deap_zip)}\n",
    "\n",
    "    print('Extracting DEAP .dat files ...')\n",
    "    with zipfile.ZipFile(deap_zip, 'r') as z:\n",
    "        dat_entries = [n for n in z.namelist() if n.endswith('.dat')]\n",
    "        print(f'  Found {len(dat_entries)} .dat files inside zip')\n",
    "        for entry in dat_entries:\n",
    "            z.extract(entry, DEAP_RAW)\n",
    "\n",
    "    for f in list(DEAP_RAW.rglob('*.dat')):\n",
    "        dest = DEAP_RAW / f.name\n",
    "        if f != dest:\n",
    "            shutil.move(str(f), str(dest))\n",
    "    for d in sorted(DEAP_RAW.rglob('*'), reverse=True):\n",
    "        if d.is_dir():\n",
    "            try: d.rmdir()\n",
    "            except OSError: pass\n",
    "\n",
    "    print(f'  ✓ DEAP: {len(list(DEAP_RAW.glob(\"*.dat\")))} .dat files ready')\n",
    "else:\n",
    "    print(f'  ✓ DEAP already extracted: {len(list(DEAP_RAW.glob(\"*.dat\")))} files')\n",
    "\n",
    "# ── IEMOCAP ──\n",
    "IEMOCAP_FILE_ID = '1lIzIlkQxwiWS4zeld-kQf87zbvPpS9gd'\n",
    "IEMOCAP_RAW = DRIVE_BASE / 'data' / 'iemocap' / 'raw'\n",
    "\n",
    "if not list(IEMOCAP_RAW.glob('Session*')):\n",
    "    iemocap_zip = DRIVE_BASE / 'data' / 'iemocap' / 'iemocap_dataset.zip'\n",
    "    if not iemocap_zip.exists():\n",
    "        !gdown --id {IEMOCAP_FILE_ID} -O {str(iemocap_zip)}\n",
    "\n",
    "    # Step 1: Extract the outer zip\n",
    "    print('Extracting IEMOCAP zip ...')\n",
    "    with zipfile.ZipFile(iemocap_zip, 'r') as z:\n",
    "        z.extractall(IEMOCAP_RAW)\n",
    "\n",
    "    # Step 2: If it contains a .tar.gz, extract that too\n",
    "    tar_files = list(IEMOCAP_RAW.rglob('*.tar.gz'))\n",
    "    for tgz in tar_files:\n",
    "        print(f'  Found inner archive: {tgz.name} — extracting (this takes a few minutes)...')\n",
    "        with tarfile.open(tgz, 'r:gz') as t:\n",
    "            t.extractall(IEMOCAP_RAW)\n",
    "        tgz.unlink()  # remove tar.gz after extraction\n",
    "        print(f'  ✓ Inner archive extracted')\n",
    "\n",
    "    # Step 3: Flatten — move Session dirs to top level if nested\n",
    "    for nested in sorted(IEMOCAP_RAW.rglob('Session*')):\n",
    "        if nested.is_dir() and nested.parent != IEMOCAP_RAW:\n",
    "            dest = IEMOCAP_RAW / nested.name\n",
    "            if not dest.exists():\n",
    "                shutil.move(str(nested), str(dest))\n",
    "\n",
    "    # Clean empty dirs\n",
    "    for d in sorted(IEMOCAP_RAW.rglob('*'), reverse=True):\n",
    "        if d.is_dir() and not any(d.iterdir()):\n",
    "            try: d.rmdir()\n",
    "            except OSError: pass\n",
    "\n",
    "    final_sessions = list(IEMOCAP_RAW.glob('Session*'))\n",
    "    print(f'  ✓ IEMOCAP: {len(final_sessions)} sessions ready')\n",
    "else:\n",
    "    print(f'  ✓ IEMOCAP already extracted: {len(list(IEMOCAP_RAW.glob(\"Session*\")))} sessions')\n",
    "\n",
    "# ── Show what's inside both datasets ──\n",
    "print('\\n' + '='*60)\n",
    "print('DEAP contents:')\n",
    "for f in sorted(DEAP_RAW.iterdir())[:10]:\n",
    "    print(f'  {f.name}  ({f.stat().st_size // 1024} KB)')\n",
    "dat_count = len(list(DEAP_RAW.glob('*.dat')))\n",
    "if dat_count > 10:\n",
    "    print(f'  ... {dat_count} .dat files total')\n",
    "\n",
    "print('\\nIEMOCAP contents:')\n",
    "for item in sorted(IEMOCAP_RAW.iterdir())[:15]:\n",
    "    tag = '[DIR]' if item.is_dir() else f'{item.stat().st_size // 1024} KB'\n",
    "    print(f'  {item.name}  ({tag})')\n",
    "    if item.is_dir():\n",
    "        for sub in sorted(item.iterdir())[:5]:\n",
    "            stag = '[DIR]' if sub.is_dir() else f'{sub.stat().st_size // 1024} KB'\n",
    "            print(f'    {sub.name}  ({stag})')\n",
    "        remaining = len(list(item.iterdir())) - 5\n",
    "        if remaining > 0:\n",
    "            print(f'    ... +{remaining} more')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850978b9",
   "metadata": {},
   "source": [
    "## 5. Verify Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3110f3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "AMERS Environment Verification\n",
      "==================================================\n",
      "\n",
      "[1] Python version\n",
      "Python 3.12.12\n",
      "\n",
      "[2] GPU\n",
      "WARNING: No GPU detected — training will be very slow.\n",
      "\n",
      "[3] Libraries\n",
      "  torch                2.10.0+cpu\n",
      "  numpy                1.26.4\n",
      "  scipy                1.16.3\n",
      "  sklearn              1.6.1\n",
      "  mne                  1.11.0\n",
      "  librosa              0.11.0\n",
      "  gymnasium            1.2.3\n",
      "  omegaconf            2.3.0\n",
      "  tqdm                 4.67.3\n",
      "  tensorboard          2.19.0\n",
      "  seaborn              0.13.2\n",
      "  matplotlib           3.10.0\n",
      "\n",
      "[4] Google Drive\n",
      "Drive mounted at /content/drive/MyDrive\n",
      "\n",
      "[5] Datasets\n",
      "  DEAP: 1 items in /content/drive/MyDrive/AMERS/data/deap/raw\n",
      "  IEMOCAP: 1 items in /content/drive/MyDrive/AMERS/data/iemocap/raw\n",
      "\n",
      "✓ Verification complete.\n"
     ]
    }
   ],
   "source": [
    "!python scripts/verify_setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee609f7",
   "metadata": {},
   "source": [
    "## 6. Pre-process Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9991e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SKIP s01.dat (not found)\n",
      "  SKIP s02.dat (not found)\n",
      "  SKIP s03.dat (not found)\n",
      "  SKIP s04.dat (not found)\n",
      "  SKIP s05.dat (not found)\n",
      "  SKIP s06.dat (not found)\n",
      "  SKIP s07.dat (not found)\n",
      "  SKIP s08.dat (not found)\n",
      "  SKIP s09.dat (not found)\n",
      "  SKIP s10.dat (not found)\n",
      "  SKIP s11.dat (not found)\n",
      "  SKIP s12.dat (not found)\n",
      "  SKIP s13.dat (not found)\n",
      "  SKIP s14.dat (not found)\n",
      "  SKIP s15.dat (not found)\n",
      "  SKIP s16.dat (not found)\n",
      "  SKIP s17.dat (not found)\n",
      "  SKIP s18.dat (not found)\n",
      "  SKIP s19.dat (not found)\n",
      "  SKIP s20.dat (not found)\n",
      "  SKIP s21.dat (not found)\n",
      "  SKIP s22.dat (not found)\n",
      "  SKIP s23.dat (not found)\n",
      "  SKIP s24.dat (not found)\n",
      "  SKIP s25.dat (not found)\n",
      "  SKIP s26.dat (not found)\n",
      "  SKIP s27.dat (not found)\n",
      "  SKIP s28.dat (not found)\n",
      "  SKIP s29.dat (not found)\n",
      "  SKIP s30.dat (not found)\n",
      "  SKIP s31.dat (not found)\n",
      "  SKIP s32.dat (not found)\n",
      "DEAP pre-processing complete.\n"
     ]
    }
   ],
   "source": [
    "# Pre-process DEAP (EEG → Differential Entropy features)\n",
    "!python scripts/preprocess_deap.py --config config/default.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc4c626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process IEMOCAP (Speech → MFCC features)\n",
    "!python scripts/preprocess_iemocap.py --config config/default.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64426c91",
   "metadata": {},
   "source": [
    "## 7. Train — Step by Step\n",
    "\n",
    "You can either run the full pipeline at once, or step through each stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c3c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Full pipeline (all stages)\n",
    "# !python scripts/train_full_pipeline.py --config config/default.yaml\n",
    "\n",
    "# Option B: Step by step (uncomment one at a time)\n",
    "\n",
    "# Step 1: Train GAN\n",
    "!python scripts/train_gan.py --config config/default.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a84bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Pre-train speech encoder\n",
    "!python scripts/train_speech.py --config config/default.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71acda77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train fusion classifier (baseline, no RL)\n",
    "!python scripts/train_fusion.py --config config/default.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a074943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train RL agent (PPO augmentation control)\n",
    "!python scripts/train_rl.py --config config/default.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35fa561",
   "metadata": {},
   "source": [
    "## 8. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51cf657",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/evaluate.py --config config/default.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7375fd3",
   "metadata": {},
   "source": [
    "## 9. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf2173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, Markdown\n",
    "\n",
    "outputs = DRIVE_BASE / 'outputs'\n",
    "\n",
    "# Confusion matrix\n",
    "cm_path = outputs / 'confusion_matrix.png'\n",
    "if cm_path.exists():\n",
    "    display(Image(str(cm_path)))\n",
    "\n",
    "# Report\n",
    "report_path = outputs / 'report.md'\n",
    "if report_path.exists():\n",
    "    display(Markdown(report_path.read_text()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897ef4fb",
   "metadata": {},
   "source": [
    "## 10. Push Updates to GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run after making changes\n",
    "# !cd /content/amers && git add -A && git commit -m 'Update from Colab' && git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
