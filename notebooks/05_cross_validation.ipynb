{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73aecf60",
   "metadata": {},
   "source": [
    "# 05 — Cross-Validation (LOSO)\n",
    "\n",
    "Leave-One-Subject-Out evaluation on DEAP (32 folds)\n",
    "and session-wise on IEMOCAP (5 folds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf025d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "os.chdir('/content/amers')\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.utils.config import load_config\n",
    "from src.utils.seed import set_seed\n",
    "\n",
    "DRIVE_BASE = Path('/content/drive/MyDrive/AMERS')\n",
    "cfg = load_config('config/default.yaml')\n",
    "set_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb70bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load per-subject data\n",
    "from src.data.deap_loader import DEAPLoader\n",
    "from src.data.label_mapper import LabelMapper\n",
    "\n",
    "processed_dir = str(DRIVE_BASE / 'data' / 'deap' / 'processed')\n",
    "loader = DEAPLoader(processed_dir=processed_dir, label_mapper=LabelMapper())\n",
    "\n",
    "features_by_subj = {}\n",
    "labels_by_subj = {}\n",
    "for s in range(1, 33):\n",
    "    feats, lbls = loader.load_subject(s)\n",
    "    if feats is not None:\n",
    "        features_by_subj[s] = feats\n",
    "        labels_by_subj[s] = lbls\n",
    "\n",
    "subjects = sorted(features_by_subj.keys())\n",
    "print(f'Loaded {len(subjects)} subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91338429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSO CV\n",
    "from src.evaluation.cross_validation import loso_cv\n",
    "from src.evaluation.metrics import compute_all_metrics\n",
    "\n",
    "# Define a simple train+eval function for EEG-only baseline\n",
    "from src.models.eeg_encoder import EEGEncoder\n",
    "from src.models.classifier import EncoderClassifier\n",
    "\n",
    "def train_and_eval(train_X, train_y, test_X, test_y, cfg):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    encoder = EEGEncoder(input_dim=160, embedding_dim=128).to(device)\n",
    "    model = EncoderClassifier(encoder, 128, 4).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    X_t = torch.as_tensor(train_X, dtype=torch.float32).to(device)\n",
    "    y_t = torch.as_tensor(train_y, dtype=torch.long).to(device)\n",
    "    \n",
    "    model.train()\n",
    "    for _ in range(20):\n",
    "        logits = model(X_t)\n",
    "        loss = criterion(logits, y_t)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_v = torch.as_tensor(test_X, dtype=torch.float32).to(device)\n",
    "        preds = model(X_v).argmax(1).cpu().numpy()\n",
    "    \n",
    "    metrics = compute_all_metrics(test_y, preds)\n",
    "    return preds, metrics\n",
    "\n",
    "# Run LOSO\n",
    "cv_results = loso_cv(\n",
    "    subjects, features_by_subj, labels_by_subj,\n",
    "    train_and_eval, cfg,\n",
    ")\n",
    "\n",
    "print(f\"\\nMean accuracy: {cv_results['mean_metrics']['accuracy']:.4f} ± {cv_results['std_metrics']['accuracy']:.4f}\")\n",
    "print(f\"Mean F1 macro: {cv_results['mean_metrics']['f1_macro']:.4f} ± {cv_results['std_metrics']['f1_macro']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27369429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-fold accuracy\n",
    "fold_accs = [m['accuracy'] for m in cv_results['fold_metrics']]\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(1, len(fold_accs)+1), fold_accs)\n",
    "plt.axhline(y=np.mean(fold_accs), color='r', linestyle='--', label=f'Mean={np.mean(fold_accs):.3f}')\n",
    "plt.xlabel('Subject')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('LOSO Per-Subject Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
